# Log Entry: 01 Feb 2026

**Focus:** File I/O, Regex Parsing, & Engineering Best Practices

### Achievements

1.  **Mastered File I/O Safety:**
    * Moved from "Brute Force" manual closing to **Context Managers** (`with open(...)`) to prevent memory leaks.
    * **Optimization:** Shifted from reading entire files (`file.read()`) to **Line-by-Line Streaming** (`for line in file:`) to handle large logs without crashing RAM.
2.  **Implemented Regex Parsing:**
    * Moved beyond simple `.split()` to using **Regular Expressions** (`re.search`) for robust pattern matching.
    * **Logic Pattern:** Learned to use **Capture Groups** `(\w+)` to extract clean data directly, avoiding the need for secondary cleanup steps.
3.  **Adopted Engineering Standards:**
    * Implemented **Guard Clauses** (`if not match: continue`) to reduce nested code and prevent "Arrow Code."
    * Understood the difference between *existence* (`if match`) and *validity* in error handling.

### Reflections & Lessons Learned

* **The "False Friend" Assumption:** I initially tried to use `file.split(":")`, assuming the file object was a string. I realized `open()` creates a "connector," and I must iterate over it to get strings.
    * *Fix:* Switched to iterating `for line in file` before applying string methods.
* **The "Ghost Key" Bug:** I tried a one-liner (`status = match ... else ""`) which accidentally counted empty strings as valid data.
    * *Improvement:* Replaced with an explicit Guard Clause to skip invalid lines entirely, ensuring data cleanliness.
* **Regex Precision:** I learned that `r'^(\w+):'` is superior to `r'^(\w+:)'` because placing the colon *outside* the capture group keeps the dictionary keys clean.

### Code Added

* `Scripts/Intermediate/log_parser.py` - (Reads "app.log", uses Regex to parse statuses, and counts frequencies safely)

### Next Steps

* Explore `collections.Counter` to further simplify the counting logic.
